{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_images import getImages\n",
    "from import_model import getModel\n",
    "from make_predictions import makePredictions\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from cellpose import resnet_torch\n",
    "from cellpose import transforms\n",
    "from cellpose import utils\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "\n",
    "from unet_architecture import UNet\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_directory = \"C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\distillCellSegTrack\\\\pipeline\\\\uploads\\\\\"\n",
    "images = getImages(images_directory)\n",
    "images_torch = torch.from_numpy(np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\distillCellSegTrack\\\\datasets\\\\Fluo-C2DL-Huh7\\\\01\\\\models\\\\CP_20230601_101328\"\n",
    "cpnet = resnet_torch.CPnet(nbase=[2,32,64,128,256],nout=3,sz=3)\n",
    "cpnet.load_model(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_pre_activations(image,cpnet):\n",
    "    rescale = cpnet.diam_mean/cpnet.diam_labels\n",
    "    shape1, shape2 = image.shape[0], image.shape[1]\n",
    "\n",
    "    x = transforms.resize_image(image, rsz=rescale,no_channels=True)\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = np.concatenate((x, x), axis=0)\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    downsample = cpnet.downsample(x)\n",
    "    print(downsample.shape)\n",
    "\n",
    "    style = cpnet.make_style(downsample[-1])\n",
    "    upsample = cpnet.upsample(style, downsample, cpnet.mkldnn)\n",
    "\n",
    "    output = cpnet.output(upsample)\n",
    "    output = output.squeeze(0)\n",
    "    output = output.cpu().detach().numpy().tolist()\n",
    "    for (k, image) in enumerate(output):\n",
    "        output[k] = cv2.resize(np.array(image), dsize=(512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    output = np.array(output)\n",
    "    output = torch.from_numpy(output)\n",
    "\n",
    "    upsample = upsample.squeeze(0)\n",
    "    upsample = upsample.cpu().detach().numpy().tolist()\n",
    "    for (k, image) in enumerate(upsample):\n",
    "        upsample[k] = cv2.resize(np.array(image), dsize=(512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    upsample = np.array(upsample)\n",
    "    upsample = torch.from_numpy(upsample)\n",
    "\n",
    "    return upsample, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_upsamples = []\n",
    "cp_outputs = []\n",
    "for image in images:\n",
    "    upsample, output = get_pre_activations(image,cpnet)\n",
    "    cp_upsamples.append(upsample)\n",
    "    cp_outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image, cellprob, cellmask):\n",
    "        self.image = image\n",
    "        self.cellprob = cellprob\n",
    "        self.cellmask = cellmask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.image[idx]\n",
    "        cellprob = self.cellprob[idx]\n",
    "        cellmask = self.cellmask[idx]\n",
    "        return img, cellprob, cellmask\n",
    "    \n",
    "train_dataset = ImageDataset(images_torch[:1], cp_upsamples[:1], cp_outputs[:1])\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha = 1.0, beta = 0.5, temperature=1):\n",
    "        super(KDLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, y_32_pred, y_3_pred, y_32_true, y_3_true):\n",
    "\n",
    "        y_32_pred = F.sigmoid(y_32_pred)\n",
    "        y_32_true = F.sigmoid(y_32_true)\n",
    "        y_32_loss = F.mse_loss(y_32_pred, y_32_true.float())\n",
    "\n",
    "        y_3_pred = F.sigmoid(y_3_pred)\n",
    "        y_3_true = F.sigmoid(y_3_true)\n",
    "        y_3_loss = F.mse_loss(y_3_pred, y_3_true.float())\n",
    "\n",
    "        loss = self.alpha * y_32_loss + self.beta * y_3_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpoch(unet, train_loader, loss_fn, optimiser, scheduler, epoch_num):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    unet.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    for image, upsample, cp_output in train_loader:\n",
    "        (image,upsample,cp_output) = (image.to('cuda:0'),upsample.to('cuda:0'),cp_output.to('cuda:0')) # sending the data to the device (cpu or GPU)\n",
    "\n",
    "        image = image.unsqueeze(1)\n",
    "        y_32_pred, y_3_pred = unet(image)\n",
    "        y_32_pred = y_32_pred.squeeze(1)\n",
    "        y_3_pred = y_3_pred.squeeze(1)\n",
    "        \n",
    "        #pred, predicted_masks, cellprob, cellmask = pred.squeeze(0), predicted_masks.float().squeeze(0), cellprob.squeeze(0), cellmask.squeeze(0)\n",
    "\n",
    "        loss = loss_fn(y_32_pred, y_3_pred, upsample, cp_output) # calculate the loss of that prediction\n",
    "\n",
    "        train_loss += loss\n",
    "        optimiser.zero_grad() # zero out the accumulated gradients\n",
    "        loss.backward() # backpropagate the loss\n",
    "        optimiser.step() # update model parameters\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "    train_loss = train_loss.item()/len(train_loader)\n",
    "\n",
    "    if epoch_num is None:\n",
    "        print('Training loss: ', train_loss, 'Time: ', time.time()-time_start)\n",
    "    else:\n",
    "        print('Epoch ', epoch_num, 'Training loss: ', train_loss, 'Time: ', time.time()-time_start)\n",
    "\n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(nbClasses=3)\n",
    "unet = unet.to('cuda:0')\n",
    "loss_fn = KDLoss()\n",
    "optimiser = torch.optim.SGD(unet.parameters(), lr=0.1, momentum=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimiser, base_lr=0.00001, max_lr=0.1)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    unet = trainEpoch(unet, train_loader, loss_fn, optimiser, scheduler=scheduler, epoch_num=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, upsample, cp_output in train_loader:\n",
    "    (image,upsample,cp_output) = (image.to('cuda:0'),upsample.to('cuda:0'),cp_output.to('cuda:0')) # sending the data to the device (cpu or GPU)\n",
    "\n",
    "    image = image.unsqueeze(1)\n",
    "    unet = unet.to('cuda:0')\n",
    "    y_32_pred, y_3_pred = unet(image)\n",
    "\n",
    "    y_3_pred = F.sigmoid(y_3_pred)\n",
    "    y_3_pred = y_3_pred.cpu().detach().numpy()\n",
    "    y_3_pred = y_3_pred.squeeze(0)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(y_3_pred[0])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(cp_output[0].cpu().detach().numpy()[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import dynamics\n",
    "\n",
    "dynamics.get_masks(y_3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid numpy array y_3_pred\n",
    "y_3_pred_2_sig = 1/(1+np.exp(-y_3_pred[2]))\n",
    "print(np.unique(y_3_pred_2_sig))\n",
    "y_3_pred_2_sig_binary = np.where(y_3_pred_2_sig>0.1,1,0)\n",
    "print(np.unique(y_3_pred_2_sig_binary))\n",
    "plt.imshow(y_3_pred_2_sig_binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(nbClasses=3)\n",
    "decfeatures, pred = unet(torch.from_numpy(images[0]).unsqueeze(0).unsqueeze(0))\n",
    "print(decfeatures.shape, pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
