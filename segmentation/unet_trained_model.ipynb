{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tifffile\n",
    "import cellpose\n",
    "from cellpose import models, io, core, dynamics\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mean\n",
    "from u_net import UNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path,normalise=False,remove_txt=False):\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "    if remove_txt:\n",
    "        onlyfiles = [val for val in onlyfiles if not val.endswith(\".txt\")]\n",
    "\n",
    "    onlyfiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "    #if num_imgs > len(onlyfiles): num_imgs = len(onlyfiles)\n",
    "    files = [np.squeeze(tifffile.imread(path +  onlyfiles[i])) for i in range(len(onlyfiles))]\n",
    "    \n",
    "    if normalise:\n",
    "        files = [(image-np.min(image))/(np.max(image)-np.min(image)) for image in files]\n",
    "    \n",
    "    return files\n",
    "    \n",
    "def get_data(path, set='01',normalise_images=True):\n",
    "\n",
    "    if len(set) == 2: #set 01 or set 02\n",
    "        images_path = path + set + '/'\n",
    "        images = get_files(images_path,normalise=normalise_images)\n",
    "        masks_path = path + set + '_GT/TRA/'\n",
    "        masks = get_files(masks_path,remove_txt=True)\n",
    "    elif set == '0102': #both sets\n",
    "        images_path = path + '01/'\n",
    "        images_01 = get_files(images_path,normalise=normalise_images)\n",
    "        images_path = path + '02/'\n",
    "        images_02 = get_files(images_path,normalise=normalise_images)\n",
    "        images = images_01 + images_02\n",
    "\n",
    "        masks_path = path + '01_GT/TRA/'\n",
    "        masks_01 = get_files(masks_path,remove_txt=True)\n",
    "        masks_path = path + '02_GT/TRA/'\n",
    "        masks_02 = get_files(masks_path,remove_txt=True)\n",
    "        masks = masks_01 + masks_02\n",
    "    else:\n",
    "        images = []\n",
    "        masks = []\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def split_image(img):\n",
    "    \n",
    "    # Split the input array into smaller arrays of size 256x256\n",
    "    sub_images = []\n",
    "    for i in range(0, img.shape[0], 256):\n",
    "        for j in range(0, img.shape[1], 256):\n",
    "            sub_img = img[i:i+256, j:j+256]\n",
    "            sub_images.append(sub_img)\n",
    "            \n",
    "    return sub_images\n",
    "\n",
    "def combine_images(sub_images):\n",
    "    \n",
    "    # Create a NumPy array of size 1024x1024 to store the combined image\n",
    "    img = np.zeros((1024, 1024))\n",
    "    \n",
    "    # Combine the smaller arrays into the larger image\n",
    "    k = 0\n",
    "    for i in range(0, img.shape[0], 256):\n",
    "        for j in range(0, img.shape[1], 256):\n",
    "            img[i:i+256, j:j+256] = sub_images[k]\n",
    "            k += 1\n",
    "            \n",
    "    return img\n",
    "\n",
    "def get_IoU(predicted_masks,gt_masks, return_list=False):\n",
    "    intersection_unions = []\n",
    "    for i in range(len(predicted_masks)):\n",
    "        intersection = np.logical_and(predicted_masks[i], gt_masks[i]).sum()\n",
    "        union = np.logical_or(predicted_masks[i], gt_masks[i]).sum()\n",
    "        intersection_unions.append(intersection/union)\n",
    "    if return_list:\n",
    "        return intersection_unions\n",
    "    return mean(intersection_unions)\n",
    "\n",
    "def get_dice(predicted_masks,gt_masks, return_list=False):\n",
    "    dices = []\n",
    "    for i in range(len(predicted_masks)):\n",
    "        intersection = np.logical_and(predicted_masks[i], gt_masks[i]).sum()\n",
    "        dice = (2*intersection)/(predicted_masks[i].sum() + gt_masks[i].sum())\n",
    "        dices.append(dice)\n",
    "    if return_list:\n",
    "        return dices\n",
    "    return mean(dices)\n",
    "\n",
    "def get_accuracy(predicted_masks,gt_masks,return_list=False):\n",
    "    accuracies = []\n",
    "    for i in range(len(predicted_masks)):\n",
    "        accuracies.append(np.mean(predicted_masks[i] == gt_masks[i]))\n",
    "    if return_list:\n",
    "        return accuracies\n",
    "    return mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = get_data(\"c:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\distillCellSegTrack\\\\\" + 'datasets/Fluo-N2DH-GOWT1/', set = '0102',normalise_images=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = [np.pad(img,((0,1024-img.shape[0]),(0,1024-img.shape[1])),mode='constant',constant_values=0) for img in X_train]\n",
    "X_test_padded = [np.pad(img,((0,1024-img.shape[0]),(0,1024-img.shape[1])),mode='constant',constant_values=0) for img in X_test]\n",
    "y_train_padded = [np.pad(img,((0,1024-img.shape[0]),(0,1024-img.shape[1])),mode='constant',constant_values=0) for img in y_train]\n",
    "y_test_padded = [np.pad(img,((0,1024-img.shape[0]),(0,1024-img.shape[1])),mode='constant',constant_values=0) for img in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarise\n",
    "y_train_padded = [np.where(img>0,1,0) for img in y_train_padded]\n",
    "y_test_padded = [np.where(img>0,1,0) for img in y_test_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split = []\n",
    "for image in X_train_padded:\n",
    "    for i in range(0, 1024, 256):\n",
    "        for j in range(0, 1024, 256):\n",
    "            sub_img = image[i:i+256, j:j+256]\n",
    "            X_train_split.append(sub_img)\n",
    "\n",
    "X_test_split = []\n",
    "for image in X_test_padded:\n",
    "    for i in range(0, 1024, 256):\n",
    "        for j in range(0, 1024, 256):\n",
    "            sub_img = image[i:i+256, j:j+256]\n",
    "            X_test_split.append(sub_img)\n",
    "\n",
    "y_train_split = []\n",
    "for mask in y_train_padded:\n",
    "    for i in range(0, 1024, 256):\n",
    "        for j in range(0, 1024, 256):\n",
    "            sub_mask = mask[i:i+256, j:j+256]\n",
    "            y_train_split.append(sub_mask)\n",
    "\n",
    "y_test_split = []\n",
    "for mask in y_test_padded:\n",
    "    for i in range(0, 1024, 256):\n",
    "        for j in range(0, 1024, 256):\n",
    "            sub_mask = mask[i:i+256, j:j+256]\n",
    "            y_test_split.append(sub_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split_rot = []\n",
    "y_train_split_rot = []\n",
    "for i in range(len(X_train_split)):\n",
    "    for j in range(4):\n",
    "        X_train_split_rot.append(np.rot90(X_train_split[i],j))\n",
    "        y_train_split_rot.append(np.rot90(y_train_split[i],j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split_rot = np.array(X_train_split_rot)\n",
    "y_train_cp_split_rot = np.array(y_train_split_rot)\n",
    "X_train_split_rot_noz = X_train_split_rot[y_train_cp_split_rot.sum(axis=(1,2))!=0]\n",
    "y_train_cp_split_rot_noz = y_train_cp_split_rot[y_train_cp_split_rot.sum(axis=(1,2))!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image, mask):\n",
    "        self.image = image\n",
    "        self.mask = mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.image[idx]\n",
    "        label = self.mask[idx]\n",
    "        return img, label\n",
    "\n",
    "X_train_torch = [torch.from_numpy(np.array(X_train_split_rot_noz[i])) for i in range(len(X_train_split_rot_noz))]\n",
    "y_train_cp_torch = [torch.from_numpy(np.array(y_train_cp_split_rot_noz[i])).type(torch.float32) for i in range(len(y_train_cp_split_rot_noz))]\n",
    "X_test_torch = [torch.from_numpy(np.array(X_test_split[i])) for i in range(len(X_test_split))]\n",
    "y_test_cp_torch = [torch.from_numpy(np.array(y_test_split[i])).type(torch.float32) for i in range(len(y_test_split))]\n",
    "train_dataset = ImageDataset(X_train_torch, y_train_cp_torch)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataset = ImageDataset(X_test_torch, y_test_cp_torch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 train loss 0.03913314916940132 test loss 0.03053106166221 IoU: 0.7409294895985893 dice: 0.8510761179937784 time:  30.822853565216064\n",
      "epoch:  1 train loss 0.03863542471359025 test loss 0.029542887533033215 IoU: 0.7413503223514488 dice: 0.8513089260051724 time:  30.853352069854736\n",
      "epoch:  2 train loss 0.03824769611805995 test loss 0.029153617652686866 IoU: 0.7391213176252958 dice: 0.8498500986899811 time:  42.391671895980835\n",
      "epoch:  3 train loss 0.037569269696786714 test loss 0.02837652129095954 IoU: 0.7466913102187824 dice: 0.8548789532741151 time:  61.607659339904785\n",
      "epoch:  4 train loss 0.03727028364820013 test loss 0.02898452088639543 IoU: 0.7448622572575819 dice: 0.8536491037295325 time:  61.55084681510925\n",
      "epoch:  5 train loss 0.03703627759205507 test loss 0.028667156760757033 IoU: 0.7403941642384259 dice: 0.8506864447626805 time:  61.31753492355347\n",
      "epoch:  6 train loss 0.03651439609812267 test loss 0.027743371757301124 IoU: 0.7470379913794415 dice: 0.8550758332594555 time:  61.02369260787964\n",
      "epoch:  7 train loss 0.03611398709099938 test loss 0.027947880126334524 IoU: 0.7384740400427465 dice: 0.8494053975896286 time:  60.429832458496094\n",
      "epoch:  8 train loss 0.03590935583053621 test loss 0.02793677755304285 IoU: 0.7453825174042846 dice: 0.8539884276057372 time:  60.86034536361694\n",
      "epoch:  9 train loss 0.035663539666865175 test loss 0.02754371552853971 IoU: 0.7457820136138066 dice: 0.8542811334070416 time:  60.71428847312927\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        (x,y) = (x.to('cuda:0'), y.to('cuda:0')) # sending the data to the device (cpu or GPU)\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        pred = model(x)# make a prediction\n",
    "        \n",
    "        y = torch.unsqueeze(y,1)\n",
    "        loss = loss_fn(pred, y) # calculate the loss of that prediction\n",
    "        train_loss += loss\n",
    "    \n",
    "        optimiser.zero_grad() # zero out the accumulated gradients\n",
    "        loss.backward() # backpropagate the loss\n",
    "        optimiser.step() # update model parameters\n",
    "    train_loss = train_loss.item()/len(train_loader)\n",
    "    \n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, cellprobs in test_loader:\n",
    "            \n",
    "            images = images.to('cuda:0')\n",
    "            cellprobs = cellprobs.to('cuda:0')\n",
    "\n",
    "            images = torch.unsqueeze(images,1)\n",
    "            cellprobs = torch.unsqueeze(cellprobs,1)\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = loss_fn(outputs, cellprobs)\n",
    "            test_loss += loss\n",
    "\n",
    "        predictions = []\n",
    "        for image in X_test_padded:\n",
    "            tiles = split_image(image)\n",
    "            tiles = np.array(tiles)\n",
    "            tiles = tiles.astype(np.float32)\n",
    "            tiles = torch.from_numpy(tiles)\n",
    "            tiles = torch.unsqueeze(tiles,1)\n",
    "            tiles = tiles.to('cuda:0')\n",
    "            outputs = model(tiles)\n",
    "            outputs = outputs.cpu().detach().numpy()\n",
    "            outputs = np.squeeze(outputs)\n",
    "            outputs = 1/(1+np.exp(-outputs))\n",
    "            outputs = np.where(outputs>0.5,1,0)\n",
    "            output = combine_images(outputs)\n",
    "            predictions.append(output)\n",
    "        IoU = get_IoU(predictions, y_test_padded)\n",
    "        dice = get_dice(predictions, y_test_padded)\n",
    "\n",
    "    test_loss = test_loss.item()/len(test_loader)\n",
    "\n",
    "    print('epoch: ', epoch, 'train loss', train_loss, 'test loss', test_loss, 'IoU:', IoU, 'dice:', dice, 'time: ', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU:  0.7457820136138066\n",
      "Max IoU:  0.7783926218708828\n",
      "Min IoU: 0.7052269808897953\n",
      "Mean Pixel-wise:  0.988216632121318\n",
      "Max Pixel-wise:  0.9906291961669922\n",
      "Min Pixel-wise:  0.9846153259277344\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for image in X_test_padded:\n",
    "    tiles = split_image(image)\n",
    "    tiles = np.array(tiles)\n",
    "    tiles = tiles.astype(np.float32)\n",
    "    tiles = torch.from_numpy(tiles)\n",
    "    tiles = torch.unsqueeze(tiles,1)\n",
    "    tiles = tiles.to('cuda:0')\n",
    "    outputs = model(tiles)\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    outputs = np.squeeze(outputs)\n",
    "    outputs = 1/(1+np.exp(-outputs))\n",
    "    outputs = np.where(outputs>0.5,1,0)\n",
    "    output = combine_images(outputs)\n",
    "    predictions.append(output)\n",
    "IoU = get_IoU(predictions, y_test_padded, return_list=True)\n",
    "accuracy = get_accuracy(predictions, y_test_padded, return_list=True)\n",
    "\n",
    "\n",
    "print('Mean IoU: ', mean(IoU))\n",
    "print('Max IoU: ', max(IoU))\n",
    "print('Min IoU:', min(IoU))\n",
    "print('Mean Pixel-wise: ', mean(accuracy))\n",
    "print('Max Pixel-wise: ', max(accuracy))\n",
    "print('Min Pixel-wise: ', min(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Block is treated as a zero-op.\n",
      "Warning: module Encoder is treated as a zero-op.\n",
      "Warning: module Decoder is treated as a zero-op.\n",
      "Warning: module UNet is treated as a zero-op.\n",
      "UNet(\n",
      "  116.75 k, 100.000% Params, 1.8 GMac, 100.000% MACs, \n",
      "  (encoder): Encoder(\n",
      "    71.79 k, 61.490% Params, 620.76 MMac, 34.437% MACs, \n",
      "    (encBlocks): ModuleList(\n",
      "      71.79 k, 61.490% Params, 618.92 MMac, 34.336% MACs, \n",
      "      (0): Block(\n",
      "        2.48 k, 2.124% Params, 163.58 MMac, 9.075% MACs, \n",
      "        (conv1): Conv2d(160, 0.137% Params, 10.49 MMac, 0.582% MACs, 1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(0, 0.000% Params, 1.05 MMac, 0.058% MACs, )\n",
      "        (conv2): Conv2d(2.32 k, 1.987% Params, 152.04 MMac, 8.435% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): Block(\n",
      "        13.89 k, 11.895% Params, 228.07 MMac, 12.652% MACs, \n",
      "        (conv1): Conv2d(4.64 k, 3.974% Params, 76.02 MMac, 4.217% MACs, 16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.029% MACs, )\n",
      "        (conv2): Conv2d(9.25 k, 7.921% Params, 151.52 MMac, 8.406% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): Block(\n",
      "        55.42 k, 47.471% Params, 227.28 MMac, 12.609% MACs, \n",
      "        (conv1): Conv2d(18.5 k, 15.842% Params, 75.76 MMac, 4.203% MACs, 32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(0, 0.000% Params, 262.14 KMac, 0.015% MACs, )\n",
      "        (conv2): Conv2d(36.93 k, 31.629% Params, 151.26 MMac, 8.391% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (pool): MaxPool2d(0, 0.000% Params, 1.84 MMac, 0.102% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    44.94 k, 38.495% Params, 1.18 GMac, 65.501% MACs, \n",
      "    (upconvs): ModuleList(\n",
      "      10.29 k, 8.812% Params, 270.01 MMac, 14.979% MACs, \n",
      "      (0): ConvTranspose2d(8.22 k, 7.044% Params, 134.74 MMac, 7.475% MACs, 64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): ConvTranspose2d(2.06 k, 1.768% Params, 135.27 MMac, 7.504% MACs, 32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (dec_blocks): ModuleList(\n",
      "      34.66 k, 29.683% Params, 910.69 MMac, 50.522% MACs, \n",
      "      (0): Block(\n",
      "        27.71 k, 23.736% Params, 454.56 MMac, 25.217% MACs, \n",
      "        (conv1): Conv2d(18.46 k, 15.815% Params, 302.51 MMac, 16.782% MACs, 64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(0, 0.000% Params, 524.29 KMac, 0.029% MACs, )\n",
      "        (conv2): Conv2d(9.25 k, 7.921% Params, 151.52 MMac, 8.406% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): Block(\n",
      "        6.94 k, 5.948% Params, 456.13 MMac, 25.304% MACs, \n",
      "        (conv1): Conv2d(4.62 k, 3.960% Params, 303.04 MMac, 16.811% MACs, 32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu): ReLU(0, 0.000% Params, 1.05 MMac, 0.058% MACs, )\n",
      "        (conv2): Conv2d(2.32 k, 1.987% Params, 152.04 MMac, 8.435% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Conv2d(17, 0.015% Params, 1.11 MMac, 0.062% MACs, 16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Computational complexity:       1.8 GMac\n",
      "Number of parameters:           116.75 k\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "  net = model\n",
    "  macs, params = get_model_complexity_info(net, (1, 256, 256), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "  print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
