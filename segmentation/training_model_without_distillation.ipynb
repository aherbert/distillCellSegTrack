{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rz200\\AppData\\Local\\anaconda3\\envs\\cellprob\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tifffile\n",
    "from u_net import UNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to split images into patches\n",
    "def split_image(img):\n",
    "    # Split the input array into smaller arrays of size 256x256\n",
    "    sub_images = []\n",
    "    for i in range(0, img.shape[0], 256):\n",
    "        for j in range(0, img.shape[1], 256):\n",
    "            sub_img = img[i:i+256, j:j+256]\n",
    "            sub_images.append(sub_img)\n",
    "    return sub_images\n",
    "\n",
    "def combine_images(sub_images):\n",
    "    # Create a NumPy array of size 1024x1024 to store the combined image\n",
    "    img = np.zeros((1024, 1024))\n",
    "    # Combine the smaller arrays into the larger image\n",
    "    k = 0\n",
    "    for i in range(0, img.shape[0], 256):\n",
    "        for j in range(0, img.shape[1], 256):\n",
    "            img[i:i+256, j:j+256] = sub_images[k]\n",
    "            k += 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting images and masks\n",
    "\n",
    "def get_files(path,normalise=False,remove_txt=False):\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "    if remove_txt:\n",
    "        onlyfiles = [val for val in onlyfiles if not val.endswith(\".txt\")]\n",
    "\n",
    "    onlyfiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "    #if num_imgs > len(onlyfiles): num_imgs = len(onlyfiles)\n",
    "    files = [np.squeeze(tifffile.imread(path +  onlyfiles[i])) for i in range(len(onlyfiles))]\n",
    "    \n",
    "    if normalise:\n",
    "        files = [(image-np.min(image))/(np.max(image)-np.min(image)) for image in files]\n",
    "    \n",
    "    return files\n",
    "\n",
    "def get_data(path, set='01',normalise_images=True):\n",
    "    if len(set) == 2: #set 01 or set 02\n",
    "        images_path = path + set + '/'\n",
    "        images = get_files(images_path,normalise=normalise_images)\n",
    "        masks_path = path + set + '_GT/TRA/'\n",
    "        masks = get_files(masks_path,remove_txt=True)\n",
    "    elif set == '0102': #both sets\n",
    "        images_path = path + '01/'\n",
    "        images_01 = get_files(images_path,normalise=normalise_images)\n",
    "        images_path = path + '02/'\n",
    "        images_02 = get_files(images_path,normalise=normalise_images)\n",
    "        images = images_01 + images_02\n",
    "\n",
    "        masks_path = path + '01_GT/TRA/'\n",
    "        masks_01 = get_files(masks_path,remove_txt=True)\n",
    "        masks_path = path + '02_GT/TRA/'\n",
    "        masks_02 = get_files(masks_path,remove_txt=True)\n",
    "        masks = masks_01 + masks_02\n",
    "    else:\n",
    "        images = []\n",
    "        masks = []\n",
    "    return images, masks\n",
    "\n",
    "images, masks = get_data(\"c:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\distillCellSegTrack\\\\\" + 'datasets/Fluo-N2DH-GOWT1/', set = '0102',normalise_images=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_padded = [np.pad(img,((0,1024-img.shape[0]),(0,1024-img.shape[1])),mode='constant',constant_values=0) for img in X_train]\n",
    "X_test_padded = [np.pad(img,((0,1024-img.shape[0]),(0,1024-img.shape[1])),mode='constant',constant_values=0) for img in X_test]\n",
    "y_train_padded = [np.pad(img,((0,1024-img.shape[0]),(0,1024-img.shape[1])),mode='constant',constant_values=0) for img in y_train]\n",
    "y_test_padded = [np.pad(img,((0,1024-img.shape[0]),(0,1024-img.shape[1])),mode='constant',constant_values=0) for img in y_test]\n",
    "#splitting images and masks into 256x256 patches\n",
    "X_train_split = []\n",
    "for image in X_train_padded:\n",
    "    for i in range(0, 1024, 256):\n",
    "        for j in range(0, 1024, 256):\n",
    "            sub_img = image[i:i+256, j:j+256]\n",
    "            X_train_split.append(sub_img)\n",
    "\n",
    "X_test_split = []\n",
    "for image in X_test_padded:\n",
    "    for i in range(0, 1024, 256):\n",
    "        for j in range(0, 1024, 256):\n",
    "            sub_img = image[i:i+256, j:j+256]\n",
    "            X_test_split.append(sub_img)\n",
    "\n",
    "y_train_split = []\n",
    "for mask in y_train_padded:\n",
    "    for i in range(0, 1024, 256):\n",
    "        for j in range(0, 1024, 256):\n",
    "            sub_mask = mask[i:i+256, j:j+256]\n",
    "            sub_mask = np.where(sub_mask>0,1,0)\n",
    "            y_train_split.append(sub_mask)\n",
    "\n",
    "y_test_split = []\n",
    "for mask in y_test_padded:\n",
    "    for i in range(0, 1024, 256):\n",
    "        for j in range(0, 1024, 256):\n",
    "            sub_mask = mask[i:i+256, j:j+256]\n",
    "            sub_mask = np.where(sub_mask>0,1,0)\n",
    "            y_test_split.append(sub_mask)\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image, mask):\n",
    "        self.image = image\n",
    "        self.mask = mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.image[idx]\n",
    "        label = self.mask[idx]\n",
    "        return img, label\n",
    "    \n",
    "X_train_split_rot = []\n",
    "y_train_cp_split_rot = []\n",
    "for i in range(len(X_train_split)):\n",
    "    for j in range(4):\n",
    "        X_train_split_rot.append(np.rot90(X_train_split[i],j))\n",
    "        y_train_cp_split_rot.append(np.rot90(y_train_split[i],j))\n",
    "X_train_split_rot = np.array(X_train_split_rot)\n",
    "y_train_cp_split_rot = np.array(y_train_cp_split_rot)\n",
    "\n",
    "X_train_split_rot_noz = X_train_split_rot[y_train_cp_split_rot.sum(axis=(1,2))!=0]\n",
    "y_train_cp_split_rot_noz = y_train_cp_split_rot[y_train_cp_split_rot.sum(axis=(1,2))!=0]\n",
    "\n",
    "X_train_torch = [torch.from_numpy(np.array(X_train_split_rot_noz[i])) for i in range(len(X_train_split_rot_noz))]\n",
    "y_train_cp_torch = [torch.from_numpy(np.array(y_train_cp_split_rot_noz[i])).type(torch.float32) for i in range(len(y_train_cp_split_rot_noz))]\n",
    "X_test_torch = [torch.from_numpy(np.array(X_test_split[i])) for i in range(len(X_test_split))]\n",
    "y_test_cp_torch = [torch.from_numpy(np.array(y_test_split[i])).type(torch.float32) for i in range(len(y_test_split))]\n",
    "train_dataset = ImageDataset(X_train_torch, y_train_cp_torch)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataset = ImageDataset(X_test_torch, y_test_cp_torch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss (3.0106934371279248e-05, 0.034585105406271445), test loss (3.0106934371279248e-05, 0.034585105406271445)\n",
      "Epoch 1: train loss (2.2340581805975453e-05, 0.03445101106489027), test loss (2.2340581805975453e-05, 0.03445101106489027)\n",
      "Epoch 2: train loss (2.0571406493817312e-05, 0.02960210877495843), test loss (2.0571406493817312e-05, 0.02960210877495843)\n",
      "Epoch 3: train loss (1.981395727662898e-05, 0.02800200436566327), test loss (1.981395727662898e-05, 0.02800200436566327)\n",
      "Epoch 4: train loss (1.9195960211092985e-05, 0.029361434884973475), test loss (1.9195960211092985e-05, 0.029361434884973475)\n",
      "Epoch 5: train loss (1.866326554179954e-05, 0.027335627658947093), test loss (1.866326554179954e-05, 0.027335627658947093)\n",
      "Epoch 6: train loss (1.822272812061981e-05, 0.026363454960487986), test loss (1.822272812061981e-05, 0.026363454960487986)\n",
      "Epoch 7: train loss (1.8035840076297076e-05, 0.02666054545222102), test loss (1.8035840076297076e-05, 0.02666054545222102)\n",
      "Epoch 8: train loss (1.763023221607147e-05, 0.02571819440738575), test loss (1.763023221607147e-05, 0.02571819440738575)\n",
      "Epoch 9: train loss (1.740124799422364e-05, 0.025014000969964104), test loss (1.740124799422364e-05, 0.025014000969964104)\n"
     ]
    }
   ],
   "source": [
    "#training the model on the masks and images\n",
    "\n",
    "def train_epoch(model, train_loader, test_loader, loss_fn, activation_fn, optimiser):\n",
    "    model.train()\n",
    "\n",
    "    #get train loss\n",
    "    total_train_loss_per_epoch = 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        #x = x.copy()\n",
    "        #y = y.copy()\n",
    "        #print(i)\n",
    "        #x = x.type(torch.float32)\n",
    "        #y = y.type(torch.float32)\n",
    "        (x,y) = (x.to('cuda:0'), y.to('cuda:0')) # sending the data to the device (cpu or GPU)\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        pred = model(x)# make a prediction\n",
    "        #sigmoid the outputs\n",
    "        if activation_fn == nn.Sigmoid:\n",
    "            pred = activation_fn(pred)\n",
    "        \n",
    "        y = torch.unsqueeze(y,1)\n",
    "        loss = loss_fn(pred, y) # calculate the loss of that prediction\n",
    "        total_train_loss_per_epoch += loss\n",
    "    \n",
    "        optimiser.zero_grad() # zero out the accumulated gradients\n",
    "        loss.backward() # backpropagate the loss\n",
    "        optimiser.step() # update model parameters\n",
    "\n",
    "        \n",
    "        #total_train_loss_per_epoch += loss.detach().item()\n",
    "\n",
    "    total_train_loss_per_epoch /= len(train_loader)\n",
    "   \n",
    "    #get test loss\n",
    "    #total_test_loss_per_epoch = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, cellprobs in test_loader:\n",
    "            #images = images.copy()\n",
    "            #cellprobs = cellprobs.copy()\n",
    "            \n",
    "            images = images.to('cuda:0')\n",
    "            cellprobs = cellprobs.to('cuda:0')\n",
    "\n",
    "            images = torch.unsqueeze(images,1)\n",
    "            cellprobs = torch.unsqueeze(cellprobs,1)\n",
    "            #cellprobs = cellprobs.to(torch.float32)\n",
    "            outputs = model(images)\n",
    "            #sigmoid the outputs\n",
    "            if activation_fn == nn.Sigmoid:\n",
    "                outputs = activation_fn(outputs)\n",
    "\n",
    "            #outputs = activation_fn(outputs)\n",
    "            loss = loss_fn(outputs, cellprobs)\n",
    "            total_loss += loss\n",
    "            #total_test_loss_per_epoch += loss.item()\n",
    "\n",
    "            #calculate dice score\n",
    "            #outputs = activation_fn(outputs)\n",
    "            #outputs = torch.where(outputs>0.5,1.0,0.0)\n",
    "            #outputs = outputs.view(-1)\n",
    "            #cellprobs = cellprobs.view(-1)\n",
    "            #intersection = (outputs * cellprobs).sum()  \n",
    "            #dice = (2.*intersection+1)/(outputs.sum() + cellprobs.sum()+1)  \n",
    "            #total_dice += dice\n",
    "            \n",
    "    #total_test_loss_per_epoch /= len(test_loader)\n",
    "    #total_dice /= len(test_loader)\n",
    "    #total_dice = total_dice.item()\n",
    "    return total_train_loss_per_epoch.item()/len(train_loader), total_loss.item()/len(test_loader)\n",
    "\n",
    "model = UNet()\n",
    "model.to('cuda:0')\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    loss = train_epoch(model, train_loader, test_loader, loss_fn, None, optimiser)\n",
    "    losses.append(loss)\n",
    "    print('Epoch {}: train loss {}, test loss {}'.format(epoch, loss, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean dice score:  0.08099949622469936\n",
      "mean iou score:  0.770016708993167\n"
     ]
    }
   ],
   "source": [
    "#testing the model's accuracy\n",
    "\n",
    "def get_prediction(image, model):\n",
    "    splitted = split_image(image)\n",
    "    predictions = []\n",
    "    for split in splitted:\n",
    "        split = torch.from_numpy(split)\n",
    "        split = split.unsqueeze(0)\n",
    "        split = split.unsqueeze(0)\n",
    "        split = split.to('cuda:0')\n",
    "        prediction = model(split)\n",
    "        prediction = prediction.squeeze(0)\n",
    "        prediction = prediction.squeeze(0)\n",
    "        predictions.append(prediction.cpu().detach().numpy())\n",
    "    combined_prediction = combine_images(predictions)\n",
    "    return combined_prediction\n",
    "\n",
    "def get_IoU(predicted_masks,gt_masks,return_list=False):\n",
    "    intersection_unions = []\n",
    "    for i in range(len(predicted_masks)):\n",
    "        intersection = np.logical_and(predicted_masks[i], gt_masks[i]).sum()\n",
    "        union = np.logical_or(predicted_masks[i], gt_masks[i]).sum()\n",
    "        intersection_unions.append(intersection/union)\n",
    "    if return_list:\n",
    "        return intersection_unions\n",
    "    return mean(intersection_unions)\n",
    "\n",
    "def get_dice(predicted_masks,gt_masks, return_list=False):\n",
    "    dices = []\n",
    "    for i in range(len(predicted_masks)):\n",
    "        intersection = np.logical_and(predicted_masks[i], gt_masks[i]).sum()\n",
    "        dice = (2*intersection)/(predicted_masks[i].sum() + gt_masks[i].sum())\n",
    "        dices.append(dice)\n",
    "    if return_list:\n",
    "        return dices\n",
    "    return mean(dices)\n",
    "\n",
    "combined_images = []\n",
    "for i in range(0, len(X_test_torch), 16):\n",
    "    combined_image = combine_images(X_test_torch[i:i+16])\n",
    "    combined_images.append(combined_image)\n",
    "\n",
    "combined_masks = []\n",
    "for i in range(0, len(y_test_cp_torch), 16):\n",
    "    combined_mask = combine_images(y_test_cp_torch[i:i+16])\n",
    "    combined_mask = np.where(combined_mask>0.4,1,0)\n",
    "    combined_masks.append(combined_mask)\n",
    "\n",
    "predictions = []\n",
    "for image in combined_images:\n",
    "    prediction = get_prediction(image, model)\n",
    "    prediction = torch.sigmoid(torch.from_numpy(prediction))\n",
    "    prediction = np.where(prediction>0.4,1,0)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "predictions_cropped = []\n",
    "for i in range(len(predictions)):\n",
    "    prediction = predictions[i]\n",
    "    mask = y_test[i]\n",
    "    prediction_cropped = prediction[0:mask.shape[0],0:mask.shape[1]]\n",
    "    predictions_cropped.append(prediction_cropped)\n",
    "\n",
    "dices = get_dice(predictions_cropped, y_test,return_list=True)\n",
    "print('mean dice score: ', np.mean(dices))\n",
    "iou = get_IoU(predictions_cropped, y_test, return_list=True)\n",
    "print('mean iou score: ', np.mean(iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "torch.save(model.state_dict(), 'train_dir/models/unet_no_distillation_GOWT1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
