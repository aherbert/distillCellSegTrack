{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tifffile\n",
    "import cellpose\n",
    "from cellpose import models, io, core, dynamics\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mean\n",
    "from u_net import UNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path,normalise=False,remove_txt=False):\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "    if remove_txt:\n",
    "        onlyfiles = [val for val in onlyfiles if not val.endswith(\".txt\")]\n",
    "\n",
    "    onlyfiles.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "    #if num_imgs > len(onlyfiles): num_imgs = len(onlyfiles)\n",
    "    files = [np.squeeze(tifffile.imread(path +  onlyfiles[i])) for i in range(len(onlyfiles))]\n",
    "    \n",
    "    if normalise:\n",
    "        files = [(image-np.min(image))/(np.max(image)-np.min(image)) for image in files]\n",
    "    \n",
    "    return files   \n",
    "   \n",
    "def get_data(path, set='01',normalise_images=True):\n",
    "\n",
    "    if len(set) == 2: #set 01 or set 02\n",
    "        images_path = path + set + '/'\n",
    "        images = get_files(images_path,normalise=normalise_images)\n",
    "        masks_path = path + set + '_GT/TRA/'\n",
    "        masks = get_files(masks_path,remove_txt=True)\n",
    "    elif set == '0102': #both sets\n",
    "        images_path = path + '01/'\n",
    "        images_01 = get_files(images_path,normalise=normalise_images)\n",
    "        images_path = path + '02/'\n",
    "        images_02 = get_files(images_path,normalise=normalise_images)\n",
    "        images = images_01 + images_02\n",
    "\n",
    "        masks_path = path + '01_GT/TRA/'\n",
    "        masks_01 = get_files(masks_path,remove_txt=True)\n",
    "        masks_path = path + '02_GT/TRA/'\n",
    "        masks_02 = get_files(masks_path,remove_txt=True)\n",
    "        masks = masks_01 + masks_02\n",
    "    else:\n",
    "        images = []\n",
    "        masks = []\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def get_IoU(predicted_masks,gt_masks, return_list=False):\n",
    "    intersection_unions = []\n",
    "    for i in range(len(predicted_masks)):\n",
    "        intersection = np.logical_and(predicted_masks[i], gt_masks[i]).sum()\n",
    "        union = np.logical_or(predicted_masks[i], gt_masks[i]).sum()\n",
    "        intersection_unions.append(intersection/union)\n",
    "    if return_list:\n",
    "        return intersection_unions\n",
    "    return mean(intersection_unions)\n",
    "\n",
    "def get_dice(predicted_masks,gt_masks, return_list=False):\n",
    "    dices = []\n",
    "    for i in range(len(predicted_masks)):\n",
    "        intersection = np.logical_and(predicted_masks[i], gt_masks[i]).sum()\n",
    "        dice = (2*intersection)/(predicted_masks[i].sum() + gt_masks[i].sum())\n",
    "        dices.append(dice)\n",
    "    if return_list:\n",
    "        return dices\n",
    "    return mean(dices)\n",
    "\n",
    "def get_accuracy(predicted_masks,gt_masks,return_list=False):\n",
    "    accuracies = []\n",
    "    for i in range(len(predicted_masks)):\n",
    "        accuracies.append(np.mean(predicted_masks[i] == gt_masks[i]))\n",
    "    if return_list:\n",
    "        return accuracies\n",
    "    return mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = get_data(\"c:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\distillCellSegTrack\\\\\" + 'datasets/Fluo-N2DH-GOWT1/', set = '0102',normalise_images=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new log file\n",
      "2023-05-11 04:27:10,380 [INFO] WRITING LOG OUTPUT TO C:\\Users\\rz200\\.cellpose\\run.log\n",
      "2023-05-11 04:27:10,381 [INFO] \n",
      "cellpose version: \t2.2.1 \n",
      "platform:       \twin32 \n",
      "python version: \t3.8.16 \n",
      "torch version:  \t1.11.0+cu113\n",
      "2023-05-11 04:27:10,389 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2023-05-11 04:27:10,391 [INFO] >> cyto << model set to be used\n",
      "2023-05-11 04:27:10,971 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n",
      "2023-05-11 04:27:17,492 [INFO] computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:12<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-11 04:27:32,699 [INFO] computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:03<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-11 04:27:37,960 [INFO] >>>> median diameter set to = 30\n",
      "2023-05-11 04:27:37,961 [INFO] >>>> mean of training label mask diameters (saved to model) 45.370\n",
      "2023-05-11 04:27:37,965 [INFO] >>>> training network with 2 channel input <<<<\n",
      "2023-05-11 04:27:37,965 [INFO] >>>> LR: 0.10000, batch_size: 16, weight_decay: 0.00010\n",
      "2023-05-11 04:27:37,966 [INFO] >>>> ntrain = 147, ntest = 37\n",
      "2023-05-11 04:27:37,966 [INFO] >>>> nimg_per_epoch = 147\n",
      "2023-05-11 04:27:44,478 [INFO] Epoch 0, Time  6.5s, Loss 0.5519, Loss Test 0.5210, LR 0.0000\n",
      "2023-05-11 04:27:50,153 [INFO] saving network parameters to train_dir\\models/cellpose_trained_model_SIM_5\n",
      "2023-05-11 04:28:14,500 [INFO] Epoch 5, Time 36.5s, Loss 0.2180, Loss Test 0.1326, LR 0.0556\n",
      "2023-05-11 04:28:44,288 [INFO] Epoch 10, Time 66.3s, Loss 0.1217, Loss Test 0.1151, LR 0.1000\n",
      "2023-05-11 04:29:43,886 [INFO] Epoch 20, Time 125.9s, Loss 0.1107, Loss Test 0.1087, LR 0.1000\n",
      "2023-05-11 04:30:43,040 [INFO] Epoch 30, Time 185.1s, Loss 0.1056, Loss Test 0.1052, LR 0.1000\n",
      "2023-05-11 04:31:42,604 [INFO] Epoch 40, Time 244.6s, Loss 0.1052, Loss Test 0.1040, LR 0.1000\n",
      "2023-05-11 04:32:42,440 [INFO] Epoch 50, Time 304.5s, Loss 0.1015, Loss Test 0.1021, LR 0.1000\n",
      "2023-05-11 04:33:41,457 [INFO] Epoch 60, Time 363.5s, Loss 0.1063, Loss Test 0.1011, LR 0.1000\n",
      "2023-05-11 04:34:40,830 [INFO] Epoch 70, Time 422.9s, Loss 0.1029, Loss Test 0.1003, LR 0.1000\n",
      "2023-05-11 04:35:30,570 [INFO] Epoch 80, Time 472.6s, Loss 0.1004, Loss Test 0.0989, LR 0.1000\n",
      "2023-05-11 04:36:15,754 [INFO] Epoch 90, Time 517.8s, Loss 0.1010, Loss Test 0.0990, LR 0.1000\n",
      "2023-05-11 04:37:00,952 [INFO] Epoch 100, Time 563.0s, Loss 0.1023, Loss Test 0.0999, LR 0.1000\n",
      "2023-05-11 04:37:05,462 [INFO] saving network parameters to train_dir\\models/cellpose_trained_model_SIM_5\n",
      "2023-05-11 04:37:46,473 [INFO] Epoch 110, Time 608.5s, Loss 0.1004, Loss Test 0.0998, LR 0.1000\n",
      "2023-05-11 04:38:31,495 [INFO] Epoch 120, Time 653.5s, Loss 0.0989, Loss Test 0.0973, LR 0.1000\n",
      "2023-05-11 04:39:16,518 [INFO] Epoch 130, Time 698.6s, Loss 0.1011, Loss Test 0.0974, LR 0.1000\n",
      "2023-05-11 04:40:01,951 [INFO] Epoch 140, Time 744.0s, Loss 0.1008, Loss Test 0.0980, LR 0.1000\n",
      "2023-05-11 04:40:47,070 [INFO] Epoch 150, Time 789.1s, Loss 0.0999, Loss Test 0.0978, LR 0.1000\n",
      "2023-05-11 04:41:32,162 [INFO] Epoch 160, Time 834.2s, Loss 0.0966, Loss Test 0.0958, LR 0.1000\n",
      "2023-05-11 04:42:17,218 [INFO] Epoch 170, Time 879.3s, Loss 0.0992, Loss Test 0.0967, LR 0.1000\n",
      "2023-05-11 04:43:02,426 [INFO] Epoch 180, Time 924.5s, Loss 0.0971, Loss Test 0.0965, LR 0.1000\n",
      "2023-05-11 04:43:47,919 [INFO] Epoch 190, Time 970.0s, Loss 0.0968, Loss Test 0.0954, LR 0.1000\n",
      "2023-05-11 04:44:28,194 [INFO] saving network parameters to train_dir\\models/cellpose_trained_model_SIM_5\n"
     ]
    }
   ],
   "source": [
    "logger = io.logger_setup()\n",
    "model = models.CellposeModel(gpu=core.use_gpu(), model_type='cyto', device=torch.device('cuda:0'))\n",
    "new_model_path = model.train(X_train, y_train, \n",
    "                              test_data=X_test,\n",
    "                              test_labels=y_test,\n",
    "                              channels=[0,0], \n",
    "                              save_path='train_dir', \n",
    "                              n_epochs=200,\n",
    "                              learning_rate=0.1,\n",
    "                              weight_decay=0.0001,\n",
    "                              model_name='cellpose_trained_model_SIM_5',\n",
    "                              batch_size=16,\n",
    "                              SGD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-11 04:44:28,591 [INFO] 0%|          | 0/37 [00:00<?, ?it/s]\n",
      "2023-05-11 04:44:29,101 [INFO] 3%|2         | 1/37 [00:00<00:18,  1.96it/s]\n",
      "2023-05-11 04:44:29,618 [INFO] 5%|5         | 2/37 [00:01<00:17,  1.95it/s]\n",
      "2023-05-11 04:44:30,151 [INFO] 8%|8         | 3/37 [00:01<00:17,  1.91it/s]\n",
      "2023-05-11 04:44:30,677 [INFO] 11%|#         | 4/37 [00:02<00:17,  1.91it/s]\n",
      "2023-05-11 04:44:31,208 [INFO] 14%|#3        | 5/37 [00:02<00:16,  1.90it/s]\n",
      "2023-05-11 04:44:31,716 [INFO] 16%|#6        | 6/37 [00:03<00:16,  1.92it/s]\n",
      "2023-05-11 04:44:32,242 [INFO] 19%|#8        | 7/37 [00:03<00:15,  1.91it/s]\n",
      "2023-05-11 04:44:32,738 [INFO] 22%|##1       | 8/37 [00:04<00:14,  1.95it/s]\n",
      "2023-05-11 04:44:33,262 [INFO] 24%|##4       | 9/37 [00:04<00:14,  1.93it/s]\n",
      "2023-05-11 04:44:33,777 [INFO] 27%|##7       | 10/37 [00:05<00:13,  1.94it/s]\n",
      "2023-05-11 04:44:34,300 [INFO] 30%|##9       | 11/37 [00:05<00:13,  1.93it/s]\n",
      "2023-05-11 04:44:34,817 [INFO] 32%|###2      | 12/37 [00:06<00:12,  1.93it/s]\n",
      "2023-05-11 04:44:35,332 [INFO] 35%|###5      | 13/37 [00:06<00:12,  1.93it/s]\n",
      "2023-05-11 04:44:35,848 [INFO] 38%|###7      | 14/37 [00:07<00:11,  1.94it/s]\n",
      "2023-05-11 04:44:36,372 [INFO] 41%|####      | 15/37 [00:07<00:11,  1.93it/s]\n",
      "2023-05-11 04:44:36,869 [INFO] 43%|####3     | 16/37 [00:08<00:10,  1.95it/s]\n",
      "2023-05-11 04:44:37,381 [INFO] 46%|####5     | 17/37 [00:08<00:10,  1.95it/s]\n",
      "2023-05-11 04:44:37,878 [INFO] 49%|####8     | 18/37 [00:09<00:09,  1.97it/s]\n",
      "2023-05-11 04:44:38,380 [INFO] 51%|#####1    | 19/37 [00:09<00:09,  1.98it/s]\n",
      "2023-05-11 04:44:38,872 [INFO] 54%|#####4    | 20/37 [00:10<00:08,  1.99it/s]\n",
      "2023-05-11 04:44:39,378 [INFO] 57%|#####6    | 21/37 [00:10<00:08,  1.99it/s]\n",
      "2023-05-11 04:44:39,894 [INFO] 59%|#####9    | 22/37 [00:11<00:07,  1.97it/s]\n",
      "2023-05-11 04:44:40,403 [INFO] 62%|######2   | 23/37 [00:11<00:07,  1.97it/s]\n",
      "2023-05-11 04:44:40,895 [INFO] 65%|######4   | 24/37 [00:12<00:06,  1.99it/s]\n",
      "2023-05-11 04:44:41,391 [INFO] 68%|######7   | 25/37 [00:12<00:06,  2.00it/s]\n",
      "2023-05-11 04:44:41,889 [INFO] 70%|#######   | 26/37 [00:13<00:05,  2.00it/s]\n",
      "2023-05-11 04:44:42,388 [INFO] 73%|#######2  | 27/37 [00:13<00:04,  2.00it/s]\n",
      "2023-05-11 04:44:42,882 [INFO] 76%|#######5  | 28/37 [00:14<00:04,  2.01it/s]\n",
      "2023-05-11 04:44:43,388 [INFO] 78%|#######8  | 29/37 [00:14<00:04,  2.00it/s]\n",
      "2023-05-11 04:44:43,885 [INFO] 81%|########1 | 30/37 [00:15<00:03,  2.00it/s]\n",
      "2023-05-11 04:44:44,391 [INFO] 84%|########3 | 31/37 [00:15<00:03,  1.99it/s]\n",
      "2023-05-11 04:44:44,886 [INFO] 86%|########6 | 32/37 [00:16<00:02,  2.00it/s]\n",
      "2023-05-11 04:44:45,391 [INFO] 89%|########9 | 33/37 [00:16<00:02,  2.00it/s]\n",
      "2023-05-11 04:44:45,892 [INFO] 92%|#########1| 34/37 [00:17<00:01,  2.00it/s]\n",
      "2023-05-11 04:44:46,404 [INFO] 95%|#########4| 35/37 [00:17<00:01,  1.98it/s]\n",
      "2023-05-11 04:44:46,904 [INFO] 97%|#########7| 36/37 [00:18<00:00,  1.99it/s]\n",
      "2023-05-11 04:44:47,404 [INFO] 100%|##########| 37/37 [00:18<00:00,  1.99it/s]\n",
      "2023-05-11 04:44:47,405 [INFO] 100%|##########| 37/37 [00:18<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_masks = model.eval(X_test, batch_size=1, channels=[0,0], diameter=model.diam_labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_masks = [np.where(mask>0,1,0) for mask in predicted_masks]\n",
    "y_test_binary = [np.where(mask>0,1,0) for mask in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU:  0.8096088846661483\n",
      "Max IoU:  0.8418616722176565\n",
      "Min IoU: 0.7799276202190316\n",
      "Mean Pixel-wise:  0.9913675978377059\n",
      "Max Pixel-wise:  0.9932928085327148\n",
      "Min Pixel-wise:  0.9885635375976562\n"
     ]
    }
   ],
   "source": [
    "IoU = get_IoU(predicted_masks,y_test_binary,return_list=True)\n",
    "accuracy = get_accuracy(predicted_masks,y_test_binary,return_list=True)\n",
    "print('Mean IoU: ', mean(IoU))\n",
    "print('Max IoU: ', max(IoU))\n",
    "print('Min IoU:', min(IoU))\n",
    "print('Mean Pixel-wise: ', mean(accuracy))\n",
    "print('Max Pixel-wise: ', max(accuracy))\n",
    "print('Min Pixel-wise: ', min(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
